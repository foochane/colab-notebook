{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer是属于常见的特征数值计算类，是一个文本特征提取方法。对于每一个训练文本，它只考虑每种词汇在该训练文本中出现的频率。\n",
    "CountVectorizer会将文本中的词语转换为词频矩阵，它通过fit_transform函数计算各个词语出现的次数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 CountVectorizer参数详解\n",
    "\n",
    "```python\n",
    "CountVectorizer(input='content', \n",
    "                encoding='utf-8',  \n",
    "                decode_error='strict', \n",
    "                strip_accents=None, \n",
    "                lowercase=True, \n",
    "                preprocessor=None, \n",
    "                tokenizer=None, \n",
    "                stop_words=None, \n",
    "                dtype=<class 'numpy.int64'>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般要设置的参数是:ngram_range,max_df，min_df，max_features等，具体情况具体分析\n",
    "\n",
    "|参数表|作用|\n",
    "|:--:|:--:|\n",
    "|input|一般使用默认即可，可以设置为\"filename’或’file’|\n",
    "|encodeing|\t使用默认的utf-8即可，分析器将会以utf-8解码raw document|\n",
    "|decode_error|\t默认为strict，遇到不能解码的字符将报UnicodeDecodeError错误，设为ignore将会忽略解码错误，还可以设为replace，作用尚不明确|\n",
    "|strip_accents|\t默认为None，可设为ascii或unicode，将使用ascii或unicode编码在预处理步骤去除raw document中的重音符号|\n",
    "|analyzer|\t一般使用默认，可设置为string类型，如’word’, ‘char’, ‘char_wb’，还可设置为callable类型，比如函数是一个callable类型|\n",
    "|preprocessor|\t设为None或callable类型|\n",
    "|tokenizer|\t设为None或callable类型|\n",
    "|ngram_range|\t词组切分的长度范围，待详解|\n",
    "|stop_words\t|设置停用词，设为english将使用内置的英语停用词，设为一个list可自定义停用词，设为None不使用停用词，设为None且max_df的float，也可以设置为没有范围限制的int，默认为1.0。这个参数的作用是作为一个阈值，当构造语料库的关键词集的时候，如果某个词的document frequence大于max_df，这个词不会被当作关键词。如果这个参数是float，则表示词出现的次数与语料库文档数的百分比，如果是int，则表示词出现的次数。如果参数中已经给定了vocabulary，则这个参数无效|\n",
    "|min_df|\t类似于max_df，不同之处在于如果某个词的document frequence小于min_df，则这个词不会被当作关键词|\n",
    "|max_features\t|默认为None，可设为int，对所有关键词的term frequency进行降序排序，只取前max_features个作为关键词集|\n",
    "|vocabulary\t|默认为None，自动从输入文档中构建关键词集，也可以是一个字典或可迭代对象？|\n",
    "|binary\t|默认为False，一个关键词在一篇文档中可能出现n次，如果binary=True，非零的n将全部置为1，这对需要布尔值输入的离散概率模型的有用的|\n",
    "|dtype|\t使用CountVectorizer类的fit_transform()或transform()将得到一个文档词频矩阵，dtype可以设置这个矩阵的数值类型|\n",
    "\n",
    "\n",
    "|属性表|\t作用|\n",
    "|:--:|:--:|\n",
    "|vocabulary_|\t词汇表；字典型|\n",
    "|get_feature_names()|\t所有文本的词汇；列表型|\n",
    "|stop_words_|\t返回停用词表|\n",
    "\n",
    "\n",
    "|方法表|\t作用|\n",
    "|--|--|\n",
    "|fit_transform(X)|\t拟合模型，并返回文本矩阵|\n",
    "|fit(raw_documents[, y])|\tLearn a vocabulary dictionary of all tokens in the raw documents.|\n",
    "|fit_transform(raw_documents[, y])|\tLearn the vocabulary dictionary and return term-document matrix.|\n",
    "\n",
    "\n",
    "用数据输入形式为列表，列表元素为代表文章的字符串，一个字符串代表一篇文章，字符串是已经分割好的。CountVectorizer同样适用于中文;\n",
    "CountVectorizer是通过fit_transform函数将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在第i个文本下的词频。即各个词语出现的次数，通过get_feature_names()可看到所有文本的关键字，通过toarray()可看到词频矩阵的结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 简单例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts=[\"dog cat fish\",\"dog cat cat\",\"fish bird\", 'bird'] # “dog cat fish” 为输入列表元素,即代表一个文章的字符串\n",
    "\n",
    "#创建词袋数据结构\n",
    "cv = CountVectorizer()\n",
    "cv_fit=cv.fit_transform(texts)\n",
    "\n",
    "#上述代码等价于下面两行\n",
    "#cv.fit(texts)\n",
    "#cv_fit=cv.transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 查看相关信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有文本的词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'cat', 'dog', 'fish']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看词汇表及索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 2, 'cat': 1, 'fish': 3, 'bird': 0}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看特征矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 2)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "print(cv_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [0 2 1 0]\n",
      " [1 0 0 1]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(cv_fit.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考链接：https://blog.csdn.net/weixin_38278334/article/details/82320307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
