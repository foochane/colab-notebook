{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 没有数字和字母的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('./data/复旦大学中文文本分类语料.xlsx','sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.715 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.enable_parallel(64) #并行分词开启\n",
    "data['文本分词'] = data['正文'].apply(lambda i:jieba.cut(i) )\n",
    "data['文本分词'] =[' '.join(i) for i in data['文本分词']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 文本标签转为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_enc = LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.分类.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(data.文本分词.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 TF-IDF提取文本特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['#NUMBER', 'al', 'betted', 'ceo', 'h_tml', 'lex', 'mon', 'nan', 'nbsp', 'sown', 'u3000', 'understands', 'understood', 'web1', '于2004', '于2005', '于2006', '于2007', '于2008', '在2004', 'ｌｉ', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def number_normalizer(tokens):\n",
    "    \"\"\" 将所有数字标记映射为一个占位符（Placeholder）。\n",
    "    对于许多实际应用场景来说，以数字开头的tokens不是很有用，\n",
    "    但这样tokens的存在也有一定相关性。 通过将所有数字都表示成同一个符号，可以达到降维的目的。\n",
    "    \"\"\"\n",
    "    return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)\n",
    "\n",
    "\n",
    "class NumberNormalizingVectorizer(TfidfVectorizer):\n",
    "    def build_tokenizer(self):\n",
    "        tokenize = super(NumberNormalizingVectorizer, self).build_tokenizer()\n",
    "        return lambda doc: list(number_normalizer(tokenize(doc)))\n",
    "\n",
    "stwlist=[line.strip() for line in open('data/停用词汇总.txt','r',encoding='utf-8').readlines()]\n",
    "\n",
    "tfv = NumberNormalizingVectorizer(min_df=3,  \n",
    "                                  max_df=0.5,\n",
    "                                  max_features=None,                 \n",
    "                                  ngram_range=(1, 2), \n",
    "                                  use_idf=True,\n",
    "                                  smooth_idf=True,\n",
    "                                  stop_words = stwlist)\n",
    "\n",
    "# 使用TF-IDF来fit训练集和测试集（半监督学习）\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把特征词保存到本地\n",
    "# import codecs\n",
    "# with codecs.open('output/tfv.txt','w',encoding='utf-8') as f:\n",
    "#         f.writelines(str(tfv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685742"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 使用模型分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"对数损失度量（Logarithmic Loss  Metric）的多分类版本。\n",
    "    :param actual: 包含actual target classes的数组\n",
    "    :param predicted: 分类预测结果矩阵, 每个类别都有一个概率\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#利用提取的TFIDF特征来fit一个简单的Logistic Regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=1.0,solver='lbfgs',multi_class='multinomial')\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 去除字母和数字的情况\n",
    "\n",
    "### 2.1 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "\n",
    "labels = []\n",
    "text = []\n",
    "with codecs.open('output/data_clean_split.txt','r',encoding='utf-8') as f:\n",
    "    document_split = f.readlines()\n",
    "    for document in document_split:\n",
    "        temp = document.split('\\t')\n",
    "        labels.append(temp[0])\n",
    "        text.append(temp[1].strip())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 标签转换为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 TF-IDF提取文本特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfv1 = TfidfVectorizer(min_df=4,  \n",
    "                       max_df=0.6)\n",
    "\n",
    "# 使用TF-IDF来fit训练集和测试集（半监督学习）\n",
    "tfv1.fit(text)\n",
    "features = tfv1.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfv1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfv1.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把特征词保存到本地\n",
    "# import codecs\n",
    "# with codecs.open('output/tfv1.txt','w',encoding='utf-8') as f:\n",
    "#         f.writelines(str(tfv1.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84412"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfv1.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_tfv, x_valid_tfv, y_train, y_valid = train_test_split(features, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 使用模型分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.564 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#利用提取的TFIDF特征来fit一个简单的Logistic Regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=1.0,solver='lbfgs',multi_class='multinomial')\n",
    "clf.fit(x_train_tfv, y_train)\n",
    "predictions = clf.predict_proba(x_valid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数统计\n",
    "这三个数参数默认就None,True,True\n",
    "```\n",
    "max_features=None,                 \n",
    "use_idf=True,\n",
    "smooth_idf=True\n",
    "```\n",
    "### 1\n",
    "```\n",
    "tfv1 = TfidfVectorizer()\n",
    "```\n",
    "logloss: 0.594 \n",
    "\n",
    "### 2\n",
    "```\n",
    "tfv1 = TfidfVectorizer(min_df=3,  \n",
    "                      max_df=0.5,\n",
    "                      max_features=None,                 \n",
    "                      ngram_range=(1, 2), \n",
    "                      use_idf=True,\n",
    "                      smooth_idf=True)\n",
    "```\n",
    "logloss: 0.605 \n",
    "\n",
    "### 3\n",
    "```\n",
    "tfv1 = TfidfVectorizer(min_df=3,  \n",
    "                      max_df=0.5,\n",
    "                      max_features=None,                 \n",
    "                      use_idf=True,\n",
    "                      smooth_idf=True)\n",
    "```\n",
    "logloss: 0.571 \n",
    "\n",
    "### 4\n",
    "```\n",
    "tfv1 = TfidfVectorizer(min_df=3,  \n",
    "                       max_df=0.8)\n",
    "```                     \n",
    "logloss: 0.571 \n",
    "\n",
    "\n",
    "### 5\n",
    "```\n",
    "tfv1 = TfidfVectorizer(min_df=4,  \n",
    "                       max_df=0.8)\n",
    "```\n",
    "logloss: 0.564 \n",
    "\n",
    "\n",
    "### 6\n",
    "```\n",
    "tfv1 = TfidfVectorizer(min_df=4,  \n",
    "                       max_df=0.5)\n",
    "```\n",
    "logloss: 0.565 \n",
    "\n",
    "### 7\n",
    "```\n",
    "tfv1 = TfidfVectorizer(min_df=4,  \n",
    "                       max_df=0.6)\n",
    "```\n",
    "logloss: 0.564 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
