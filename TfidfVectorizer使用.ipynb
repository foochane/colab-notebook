{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 构造文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# text = ['手机不错，是我喜欢的款，下手了!!!',\n",
    "#         '今天去苹果手机店试玩，觉得iPhoneSE真的很鸡肋',\n",
    "#         '非常好，我就喜欢4英寸的手机，而且运行起来也非常快，价格也还行'\n",
    "#         ]\n",
    "text = ['机器学习是人工智能的一个分支。',\n",
    "        '机器学习是对能通过经验自动改进的计算机算法的研究。',\n",
    "        '机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.718 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "# text_split = [''.join(i) for i in [jieba.cut(t) for t in text]]\n",
    "\n",
    "text_split = []\n",
    "jieba.enable_parallel(64) #并行分词开启\n",
    "for t in text:\n",
    "    tmp = jieba.cut(t) \n",
    "    tmp_split = [''.join(i) for i in tmp]\n",
    "    split = ' '.join(i for i in tmp_split)\n",
    "    text_split.append(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['机器 学习 是 人工智能 的 一个 分支 。', '机器 学习 是 对 能 通过 经验 自动 改进 的 计算机 算法 的 研究 。', '机器 学习 是 实现 人工智能 的 一个 途径 ， 即以 机器 学习 为 手段 解决 人工智能 中 的 问题 。']\n"
     ]
    }
   ],
   "source": [
    "print(text_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 使用TfidfVectorizer构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfvector = TfidfVectorizer()\n",
    "model = tfvector.fit(text_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的特征词:['一个', '人工智能', '分支', '即以', '学习', '实现', '手段', '改进', '机器', '研究', '算法', '经验', '自动', '解决', '计算机', '途径', '通过', '问题']\n"
     ]
    }
   ],
   "source": [
    "print(\"提取的特征词:\" + str(model.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征词和索引:{'机器': 8, '学习': 4, '人工智能': 1, '一个': 0, '分支': 2, '通过': 16, '经验': 11, '自动': 12, '改进': 7, '计算机': 14, '算法': 10, '研究': 9, '实现': 5, '途径': 15, '即以': 3, '手段': 6, '解决': 13, '问题': 17}\n"
     ]
    }
   ],
   "source": [
    "print(\"特征词和索引:\" + str(model.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征词的个数是18,对应的索引为0到17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 获取tf-idf矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = model.transform(text_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 矩阵的shape\n",
    "\n",
    "矩阵是3行18列，也就是有3个文档，每个文档有18个特征词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 18)\n"
     ]
    }
   ],
   "source": [
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 查看矩阵的内容\n",
    "这是个稀疏矩阵，如(0,8)表示第0个文档，第8个特征词(从0开始)的权重值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.3495777539781596\n",
      "  (0, 4)\t0.3495777539781596\n",
      "  (0, 2)\t0.5918865885345992\n",
      "  (0, 1)\t0.45014500672563534\n",
      "  (0, 0)\t0.45014500672563534\n",
      "  (1, 16)\t0.3604298781233275\n",
      "  (1, 14)\t0.3604298781233275\n",
      "  (1, 12)\t0.3604298781233275\n",
      "  (1, 11)\t0.3604298781233275\n",
      "  (1, 10)\t0.3604298781233275\n",
      "  (1, 9)\t0.3604298781233275\n",
      "  (1, 8)\t0.21287569223847908\n",
      "  (1, 7)\t0.3604298781233275\n",
      "  (1, 4)\t0.21287569223847908\n",
      "  (2, 17)\t0.2925701011880934\n",
      "  (2, 15)\t0.2925701011880934\n",
      "  (2, 13)\t0.2925701011880934\n",
      "  (2, 8)\t0.3455932296344571\n",
      "  (2, 6)\t0.2925701011880934\n",
      "  (2, 5)\t0.2925701011880934\n",
      "  (2, 4)\t0.3455932296344571\n",
      "  (2, 3)\t0.2925701011880934\n",
      "  (2, 1)\t0.4450142061610019\n",
      "  (2, 0)\t0.22250710308050095\n"
     ]
    }
   ],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接查看具体的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45014501 0.45014501 0.59188659 0.         0.34957775 0.\n",
      "  0.         0.         0.34957775 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21287569 0.\n",
      "  0.         0.36042988 0.21287569 0.36042988 0.36042988 0.36042988\n",
      "  0.36042988 0.         0.36042988 0.         0.36042988 0.        ]\n",
      " [0.2225071  0.44501421 0.         0.2925701  0.34559323 0.2925701\n",
      "  0.2925701  0.         0.34559323 0.         0.         0.\n",
      "  0.         0.2925701  0.         0.2925701  0.         0.2925701 ]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 TfidfVectorizer的参数说明\n",
    "- token_pattern ：可以添加正则表达式，如 `token_pattern=r\"(?u)\\b\\w+\\b\")`可以匹配到单个子，如果为`r\"(?u)\\b\\w\\w+\\b\"`则会只匹配两个子以上的词。\n",
    "\n",
    "- max_df：浮点数：[0.0,1.0]，如0.4，若某词语在的样本点中出现的概率超40%，则生成字典时剔除该词语；默认是1.0,即不剔除。\n",
    "- min_df：整数：n。若某词语样本点中出现的次数小于n，生成字典时剔除该词语。默认是1，表明若词语只在1个以下文档中出现，剔除。\n",
    "- max_features：整数：n。根据词语的TF-IDF权重降序排列，取前面n个最高值的词语组成词典。默认是None，即取全部词语。\n",
    "- stop_words：指定停止词\n",
    "- ngram_range: tuple(min_n, max_n) 要提取的n-gram的n-values的下限和上限范围，在min_n <= n <= max_n区间的n的全部值\n",
    "- smooth_idf：boolean通过加1到文档频率平滑idf权重，为防止除零，加入一个额外的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stwlist = ['的','一个','是','。']\n",
    "tfvector = TfidfVectorizer(min_df=1,  \n",
    "                           max_df=0.5,\n",
    "                           max_features=None,                 \n",
    "                           ngram_range=(1, 2), \n",
    "                           use_idf=True,\n",
    "                           smooth_idf=True,\n",
    "                           stop_words = stwlist)\n",
    "model = tfvector.fit(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
